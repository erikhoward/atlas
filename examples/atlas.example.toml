# Atlas Configuration Example
# This is a sample configuration file for Atlas ETL tool

[application]
name = "atlas"
version = "1.0.0"
log_level = "info" # trace, debug, info, warn, error
dry_run = false

[openehr]
# EHRBase server endpoint
base_url = "https://ehrbase.example.com/ehrbase/rest/openehr/v1"
vendor = "ehrbase"                                               # Vendor-specific implementation

# Authentication
auth_type = "basic"                    # basic | openid (future)
username = "atlas_user"
password = "${ATLAS_OPENEHR_PASSWORD}" # Env var substitution

# TLS settings
tls_verify = true
# tls_ca_cert = "/path/to/ca.crt"  # Optional

[openehr.query]
# Export filters
template_ids = ["IDCR - Adverse Reaction List.v1", "IDCR - Problem List.v1"]
ehr_ids = []                                                                 # Empty = all EHRs
time_range_start = "2024-01-01T00:00:00Z"                                    # ISO 8601 or null
time_range_end = null                                                        # null = now

# Batch processing
batch_size = 1000 # 100-5000
parallel_ehrs = 8 # Concurrent EHR processing
[export]
mode = "incremental"                   # full | incremental
export_composition_format = "preserve" # preserve | flatten

# Retry settings
max_retries = 3
retry_backoff_ms = [1000, 2000, 4000] # Exponential backoff

[cosmosdb]
# Connection
endpoint = "https://myaccount.documents.azure.com:443/"
key = "${ATLAS_COSMOS_KEY}"
database_name = "openehr_data"

# Container settings
control_container = "atlas_control"
data_container_prefix = "compositions" # Results in: compositions_{template_id}

# Partitioning
partition_key = "/ehr_id"

# Performance
max_concurrency = 10
request_timeout_seconds = 60

[state]
# State management
enable_checkpointing = true
checkpoint_interval_seconds = 30

[verification]
# Optional data verification
enable_verification = false
checksum_algorithm = "sha256"

[logging]
# Local logging
local_enabled = true
local_path = "/var/log/atlas"
local_rotation = "daily"      # daily | size
local_max_size_mb = 100

# Azure Log Analytics (optional)
azure_enabled = false
# azure_tenant_id = "${AZURE_TENANT_ID}"
# azure_client_id = "${AZURE_CLIENT_ID}"
# azure_client_secret = "${AZURE_CLIENT_SECRET}"
# azure_log_analytics_workspace_id = "${AZURE_LOG_ANALYTICS_WORKSPACE_ID}"
# azure_dcr_immutable_id = "${AZURE_DCR_IMMUTABLE_ID}"
# azure_dce_endpoint = "${AZURE_DCE_ENDPOINT}"
# azure_stream_name = "Custom-AtlasExport_CL"
